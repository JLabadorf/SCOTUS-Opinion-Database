{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Author: James Labadorf\n",
    "# Github: jlabadorf\n",
    "# Email: jslabad+github@gmail.com\n",
    "# License: CC-BY-2.0 (https://creativecommons.org/licenses/by/2.0/)\n",
    "# Datasource: Free Law Project, Bulk Opinions (https://www.courtlistener.com/api/bulk-data/opinions/scotus.tar.gz)\n",
    "# Description: This code takes the data downloaded from the datasources and combines them into a single database table.\n",
    "##################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_text(html): #Sometimes the plain text is not available but the HTML is. This function extracts the plain text from the HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        text = soup.find_all(text=True)\n",
    "        text\n",
    "        fulltext = \"\"\n",
    "        for line in text:\n",
    "            fulltext += line\n",
    "        return fulltext\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "import requests as r\n",
    "\n",
    "def get_author(uri): #The author field is returned as a URI. This function pings the API and returns the human reable information\n",
    "    try:\n",
    "        auth = r.get(uri)\n",
    "        auth.text\n",
    "\n",
    "        auth = json.loads(auth.text)\n",
    "        person_id = auth[\"id\"]\n",
    "        return (auth[\"slug\"],person_id)\n",
    "    except:\n",
    "        return (None,None)\n",
    "\n",
    "\n",
    "#First, I need to get the file paths for all the cases\n",
    "\n",
    "###################### Get Files #######################\n",
    "### Code block source: https://pythonguides.com/python-get-all-files-in-directory/\n",
    "path = str(os.getcwd())+u\"\\\\all_cases\" \n",
    "list_of_files = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "\tfor file in files:\n",
    "\t\tlist_of_files.append(os.path.join(root,file))\n",
    "#########################################################\n",
    "\n",
    "#Secondly, I need to convert the jsons to a format I can utilize.\n",
    "\n",
    "data = []\n",
    "\n",
    "############## Open the JSONs ###########################\n",
    "for file in list_of_files:\n",
    "    try:\n",
    "        with open(file) as opinion:\n",
    "            o_dict = json.load(opinion)\n",
    "\n",
    "#########################################################\n",
    "#################### Extract data  ######################\n",
    "        id = o_dict[\"id\"]\n",
    "        resource_uri = o_dict[\"resource_uri\"]\n",
    "        #author_tup = get_author(o_dict[\"author\"]) # removed this option not to overwhelm the Free Law API\n",
    "        #author = author_tup[0]\n",
    "        try:\n",
    "            author_id = o_dict[\"author\"][-5:-1]\n",
    "        except:\n",
    "            author_id = None\n",
    "        author_uri = o_dict[\"author\"]\n",
    "        joined_by = o_dict[\"joined_by\"]\n",
    "        per_curiam = o_dict[\"per_curiam\"]\n",
    "        type = o_dict[\"type\"]\n",
    "        sha1 = o_dict[\"sha1\"]\n",
    "        page_count = o_dict[\"page_count\"]\n",
    "        download_url = o_dict[\"download_url\"]\n",
    "        date_created = o_dict[\"date_created\"]\n",
    "        date_modified = o_dict[\"date_modified\"]\n",
    "        plain_text = o_dict[\"plain_text\"]\n",
    "        html = o_dict[\"html\"]\n",
    "        if o_dict[\"plain_text\"] =='':\n",
    "            plain_text = get_text(html)\n",
    "        data.append([id,resource_uri,author_id,author_uri,author,joined_by,per_curiam,type,sha1,page_count,download_url,date_created,date_modified,plain_text,html])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "###########################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Sqlite3.db formed.\n"
     ]
    }
   ],
   "source": [
    "# Lastly, we need to package the data and send it to the database\n",
    "\n",
    "columns = [\"id\",\"resource_uri\",\"author_id\",\"author_uri\",\"author\",\"joined_by\",\"per_curiam\",\"type\",\"sha1\",\"page_count\",\"download_url\",\"date_created\",\"date_modified\",\"plain_text\",\"html_text\"]\n",
    "df = pd.DataFrame(data,columns=columns)\n",
    "\n",
    "### Code block source: https://www.geeksforgeeks.org/python-sqlite-creating-a-new-database/\n",
    "\n",
    "import sqlite3\n",
    "  \n",
    "# filename to form database\n",
    "\n",
    "file = \"Sqlite3.db\"\n",
    "df = df.applymap(str)\n",
    "try:\n",
    "  conn = sqlite3.connect(file)\n",
    "  print(\"Database Sqlite3.db formed.\")\n",
    "except:\n",
    "  print(\"Database Sqlite3.db not formed.\")\n",
    "#### end code block #####\n",
    "\n",
    "\n",
    "df.to_sql(name = \"opinion_table\",con=conn, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c644d696b95f5e0f4df3c6556741cf30bcf9ea6ca93c3e1f29fcf31d885534fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
